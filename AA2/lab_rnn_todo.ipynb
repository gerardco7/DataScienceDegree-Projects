{"cells":[{"cell_type":"markdown","metadata":{"id":"bNgvzqC1IBjH"},"source":["# Recurrent Neural Networks\n","\n","## Lab credit\n","Created by [Santiago Pascual](https://scholar.google.es/citations?user=7cVOyh0AAAAJ&hl=ca) and [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) in [UPC School](https://www.talent.upc.edu/ing/) (2019).\n","\n","Updated by [Gerard I. Gállego](https://www.linkedin.com/in/gerard-gallego/) in 2021, and by [Javier Ferrando](https://www.linkedin.com/in/javierferrandomonsonis/) in 2022.\n"]},{"cell_type":"markdown","metadata":{"id":"PqBBz46awSAh"},"source":["# The Fault in Our Time\n","\n","This lab session introduces our beloved friends, the [recurrent neural networks (RNNs)](https://en.wikipedia.org/wiki/Recurrent_neural_network). Concretely, the topology we will be seeing is the Elman type, nowadays widely known plainly as RNN. Recurrent neural networks are the super cool queens of sequences: they know about order in sequences. As a quick test for how important sequential context is, and to prove that it is also very important for you... **CAN YOU TELL THE SIXTH DIGIT OF YOUR MOBILE PHONE NUMBER? WHAT PROCESS ARE YOU FOLLOWING TO RECALL IT?** Exactly, you went straight from the beginning of the full sequence, hence this is how important sequences are to us too :)\n","\n","As in the example before, we always work with sequences when using RNNs. In each batch of data, we have as many elements as the length of the sequence (seq_len), and each of these elements can contain multiple features (num_feats):\n","\n","<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/input_batch.png?raw=true\" class=\"center\" title=\"input batch\" width=\"300\"/>\n","</p><br>\n","\n","A fully connected layer is defined as:\n","\n","$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{b})$\n","\n","With \"only one\" (but super important) change we formulate the RNN:\n","\n","$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{U}\\boldsymbol{h}_{t-1} + \\boldsymbol{b})$\n","\n","Exactly, we added the matrix $\\boldsymbol{U}$ which is a set of connections among all the neurons from the hidden layers to themselves (hence a feedback)!\n","\n","This looks like the following, which is typically unrolled in time to show both flows of data, feed-forward ($\\boldsymbol{W}$) + time ($\\boldsymbol{U}$):\n","\n","<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/one_layer_rnn.png?raw=true\" class=\"center\" title=\"one layer RNN\" width=\"300\"/>\n","</p><br>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"nyehAEtvlLoS","executionInfo":{"status":"ok","timestamp":1669980356852,"user_tz":-60,"elapsed":3286,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}}},"outputs":[],"source":["# Let's first import the typical stuff to play with deep nets\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.optim as optim\n","import matplotlib\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from timeit import default_timer as timer\n","\n","torch.manual_seed(1)\n","device = 'cpu'\n","if torch.cuda.is_available():\n","  device = 'cuda'\n","  torch.cuda.manual_seed_all(1)"]},{"cell_type":"markdown","metadata":{"id":"e8YHdo2o0Ago"},"source":["### Exercise 1: Building a recurrent neural layer\n","\n","In the next cell, we will define our own unidirectional RNN layer. The class `MyUnidirectionalRNN` must make use of `nn.Linear` layers to make the feed-forward and time projections, and use the `nn.Parameter` class to build the biases. Please build the recurrent neural component with the addition of the recurrent connections.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ps7x6QEClLoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669980491425,"user_tz":-60,"elapsed":220,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"61c9dcae-ebff-4e04-ecf2-68da3a73ba46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success! Output shape: 5 sequences, each of length 15, each token with 32 dims\n"]}],"source":["class MyUnidirectionalRNN(nn.Module):\n","\n","  def __init__(self, num_feats, rnn_size=128):\n","    super().__init__()\n","    self.rnn_size = rnn_size\n","\n","    # Definition of the RNN parameters with the use of Linear layers:\n","\n","    # Define the input activation matrix W\n","    self.W = nn.Linear(num_feats, rnn_size, bias=False)\n","\n","    # TODO: Define the hidden activation matrix U\n","    self.U = nn.Linear(rnn_size, rnn_size, bias=False)\n","\n","    # Define the bias\n","    self.b = nn.Parameter(torch.zeros(1, rnn_size))\n","\n","  def forward(self, x, state=None):\n","    # Assuming x is of shape [batch_size, seq_len, num_feats]\n","    xs = torch.chunk(x, x.shape[1], dim=1)\n","    hts = []\n","    if state is None:\n","      state = self.init_state(x.shape[0])\n","    ht = state\n","    for xt in xs:\n","      # turn x[t] into shape [batch_size, num_feats] to be projected\n","      xt = xt.squeeze(1)\n","      ct = self.W(xt)\n","      ct = ct + self.U(ht)\n","      ht = ct + self.b\n","      # give the temporal dimension back to h[t] to be cated\n","      hts.append(ht.unsqueeze(1))\n","    hts = torch.cat(hts, dim=1)\n","    return hts\n","\n","  def init_state(self, batch_size):\n","    return torch.zeros(batch_size, self.rnn_size)\n","\n","# To correctly assess the answer, we build an example RNN with 10 inputs and 32 neurons\n","rnn = MyUnidirectionalRNN(10, 32)\n","# Then we will forward some random sequences, each of length 15\n","xt = torch.randn(5, 15, 10)\n","# The returned tensor will be h[t]\n","ht = rnn(xt)\n","assert ht.shape[0] == 5 and ht.shape[1] == 15 and ht.shape[2] == 32, \\\n","'Something went wrong within the RNN :('\n","print('Success! Output shape: {} sequences, each of length {}, each '\\\n","      'token with {} dims'.format(ht.shape[0], ht.shape[1], ht.shape[2]))"]},{"cell_type":"markdown","metadata":{"id":"THnEZ6UmPAJU"},"source":["### But Why Would You Do That?\n","\n","Congratz on finishing your first RNN definition! Now you should understand a bit more on the intrinsics of our sequential friends. But why would you define your own RNN? We didn't even operate with a GPU. We didn't even consider that possibility. So in the real world, we use PyTorch's `nn.RNN`, which allows for building a **stack of RNN layers directly**. Let's see some examples:"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"OXKC-zZ-lLoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669985323191,"user_tz":-60,"elapsed":206,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"88b7fd8a-ce4d-4986-ff48-dcffb0f285f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["RNN(10, 64)\n","Output h[t] tensor shape:  torch.Size([25, 10, 64])\n","Output state tensor shape:  torch.Size([1, 10, 64])\n"]}],"source":["# we will work with 10 input features\n","NUM_FEATS = 10\n","# and sequences of length 25\n","SEQ_LEN = 25\n","# and 5 samples per batch\n","BATCH_SIZE = 5 \n","# and 128 neurons\n","HIDDEN_SIZE = 64\n","\n","# The first RNN contains a single layer\n","rnn1 = nn.RNN(NUM_FEATS, HIDDEN_SIZE)\n","print(rnn1)\n","\n","# Now let's build a random input tensor to forward through it\n","xt = torch.randn(SEQ_LEN, 10, NUM_FEATS)\n","ht, state = rnn1(xt)\n","print('Output h[t] tensor shape: ', ht.shape)\n","print('Output state tensor shape: ', state.shape)"]},{"cell_type":"markdown","metadata":{"id":"eg4c-TaLQ5Ag"},"source":["#### OK STOP IT HERE, We've got to talk\n","\n","Think about how many things are happening in the previous cell. First, we define some hyper-parameters to define the input tensor shape and the RNN size. Then, we build one RNN layer. Then, we build random data. Finally, we forward the random data, and what is returned? Why does the input tensor `x` have that shape? Why is the RNN returning 2 output values?\n","\n","**First answer:** The input data to an RNN can be shaped in 2 formats: `batch_first=True` and `batch_first=False`. As its name indicates, when it is `False`, the `batch_size` dimension is not the first but the second one. Then which is the first one? The `sequence_length`. If we do not specify anything, by default `batch_first=False`, so the tensor $\\boldsymbol{x}_t$ must have the dimensions: [`seq_len`, `batch_size`, `num_feats`]. We normally use `batch_first=True` to couple the RNN easily with other layers like the `nn.Linear` one.\n","\n","### Exercise 2\n","\n","Find the second answer on \"**Why is the RNN returning 2 output values?**\". Understand what is the `state` output and answer: \"**what does it contain?**\". Your source of knowledge is in the following URL, where the outputs description for the `RNN` module is given: https://pytorch.org/docs/stable/nn.html#torch.nn.RNN\n","\n","(D∗num_layers,N,H_out) containing the final hidden state for each element in the batch.\n"]},{"cell_type":"markdown","metadata":{"id":"1wAY1wWTT3pR"},"source":["Now we can continue defining some more examples of RNN layers as promised before"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"bA21WrmilLof","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669985250886,"user_tz":-60,"elapsed":260,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"9c8f5915-eb3e-43f8-9f44-20f732dd764d"},"outputs":[{"output_type":"stream","name":"stdout","text":["RNN 2 layers >> ht.shape:  torch.Size([25, 10, 64])\n","RNN 2 layers >> state.shape:  torch.Size([2, 10, 64])\n","RNN 2 layers, batch_first >> ht.shape:  torch.Size([5, 25, 64])\n","RNN 2 layers, batch_first >> state.shape:  torch.Size([2, 5, 64])\n"]}],"source":["# 2 Layer RNN\n","rnn2 = nn.RNN(NUM_FEATS, HIDDEN_SIZE, num_layers=2)\n","ht, state = rnn2(xt)\n","print('RNN 2 layers >> ht.shape: ', ht.shape)\n","print('RNN 2 layers >> state.shape: ', state.shape)\n","\n","\n","# Batch Size first RNN\n","xt_bf = torch.randn(BATCH_SIZE, SEQ_LEN, NUM_FEATS)\n","rnn3 = nn.RNN(NUM_FEATS, 64, num_layers=2, batch_first=True)\n","ht, state = rnn3(xt_bf)\n","print('RNN 2 layers, batch_first >> ht.shape: ', ht.shape)\n","print('RNN 2 layers, batch_first >> state.shape: ', state.shape)"]},{"cell_type":"markdown","metadata":{"id":"aNGrWTyorkNg"},"source":["<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/two_layers_rnn.png?raw=true\" class=\"center\" title=\"two layers RNN\" width=\"300\"/>\n","</p><br>"]},{"cell_type":"markdown","metadata":{"id":"cfRkpNiOUwxA"},"source":["### Exercise 3.1\n","Build a **bidirectional RNN with 3 layers** by completing the TODO in the code."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"PAwoUR_qlLoi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669985391889,"user_tz":-60,"elapsed":305,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"194d1c0d-e2b8-48ff-ab15-172995b78387"},"outputs":[{"output_type":"stream","name":"stdout","text":["Bidirectional RNN layer >> bi_ht.shape:  torch.Size([5, 25, 128])\n","Bidirectional RNN layer >> bi_state.shape:  torch.Size([6, 25, 64])\n"]}],"source":["# TODO: build the bidirectional RNN layer\n","bi_rnn = nn.RNN(NUM_FEATS, HIDDEN_SIZE, num_layers=3, bidirectional = True)\n","\n","# forward xt_bf\n","bi_ht, bi_state = bi_rnn(xt_bf)\n","print('Bidirectional RNN layer >> bi_ht.shape: ', bi_ht.shape)\n","print('Bidirectional RNN layer >> bi_state.shape: ', bi_state.shape)"]},{"cell_type":"markdown","metadata":{"id":"fDE81Z2XKN2J"},"source":["### Exercise 3.2\n","What is the output $\\boldsymbol{h}_t$ shape and why?\n","\n","(N,L,D∗Hout)\n","\n","### Exercise 3.3\n","What is the output `state` shape and why?\n","\n","(D∗num_layers,N,Hout) \n","\n"]},{"cell_type":"markdown","metadata":{"id":"HgKP_9eKTQcp"},"source":["### Hold The Gates! A Recurrent Re-Evolution\n","\n","You've surely heard about the `LSTM` or the `GRU`, two practically sibling recurrent models. Well those are the actual RNNs you will use in your everyday. Why? Because they:\n","1. Improve the memory capacity of the RNN.\n","2. Improve the gradient flow of vanilla RNNs thanks to the learnable gate mechanisms.\n","\n","An LSTM or GRU cell is a composition of different neurons working jointly, and the whole thing replaces a single RNN neuron. The RNN cell (with one $\\tanh$ neuron), the LSTM cell and the GRU cell are depicted in the following figure from [this article](https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwiMiPbfoPHlAhUQCxoKHW9qA04Qjhx6BAgBEAI&url=http%3A%2F%2Fdprogrammer.org%2Frnn-lstm-gru&psig=AOvVaw3mU76KRvFfY9WiOF4N12ex&ust=1574080203478260):\n","\n","![lstm](http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU-1200x361.png)\n","\n","Now check that out. In the case of the LSTM, we have **two signals flowing in time** apart from the feed-forward input per time-step: $\\boldsymbol{c}_t$ and $\\boldsymbol{h}_t$. The first one is called the cumulative cell state. It basically will add everything it is \"allowed to see\" from the input, and will forget portions of it. This is unbounded. On the other hand, the output cell state $\\boldsymbol{h}_t$ will be the final layer activation (what is allowed to come out of it). This is bounded [-1, 1]."]},{"cell_type":"markdown","metadata":{"id":"4WhMLsykdUEq"},"source":["### Exercise 4: An LSTM Character-based Language Model\n","\n","In this final exercise we will train a language model that will work at the character level. This is, a neural network based on an RNN architecture that will complete language (textual) sequences.\n"]},{"cell_type":"markdown","metadata":{"id":"KFGtDsWkUZoK"},"source":["Our dataset will be composed of scripts from the *Friends* TV show. Download the episode 1 trainset:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TP0-6NLClLop","executionInfo":{"status":"ok","timestamp":1669981213628,"user_tz":-60,"elapsed":307,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}}},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/telecombcn-dl/labs-all/master/labs/rnn/episode1_english.txt"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Q3b6NzjtlLop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669981225317,"user_tz":-60,"elapsed":1034,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"91126849-4ed8-481c-810d-b38f0510287b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of found vocabulary tokens:  67\n"]}],"source":["# Let's prepare some synthetic data\n","\n","def prepare_sequence(seq, char2idx, onehot=True):\n","    # convert sequence of words to indices\n","    idxs = [char2idx[c] for c in seq]\n","    idxs = torch.tensor(idxs, dtype=torch.long)\n","    if onehot:\n","      # conver to onehot (if input to network)\n","      ohs = F.one_hot(idxs, len(char2idx)).float()\n","      return ohs\n","    else:\n","      return idxs\n","\n","with open('episode1_english.txt', 'r') as txt_f:\n","  training_data = [l.rstrip() for l in txt_f if l.rstrip() != '']\n","\n","# merge ºe\n","training_data = '$'.join(training_data)\n","\n","# Assign a unique ID to each different character found in the training set\n","char2idx = {}\n","for sent in training_data:\n","    for c in sent:\n","        if c not in char2idx:\n","            char2idx[c] = len(char2idx)\n","idx2char = dict((v, k) for k, v in char2idx.items())\n","VOCAB_SIZE = len(char2idx)\n","RNN_SIZE = 1024\n","MLP_SIZE = 2048\n","SEQ_LEN = 50\n","print('Number of found vocabulary tokens: ', VOCAB_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"Ehk_6JNIkZOs"},"source":["##### Exercise 4.1\n","* What is the amount of outputs needed by the character prediction model?\n","67\n","\n","##### Exercise 4.2\n","* What is the proper activation to plug on top of the MLP (if any)? (Note that we use `NLLLoss` later on).\n","softmax\n","\n","##### Exercise 4.3\n","* Finish the definition of the `CharLSTM` model to include a `nn.LSTM` layer, with `batch_first=True`, `vocab_size` inputs and `rnn_size` cells, and an MLP that projects the `rnn_size` to `mlp_size` with one `ReLU` hidden layer and then to the appropriate amount of outputs. Put a `Dropout(0.4)` after the `ReLU`. \n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"NqElh0COlLor","executionInfo":{"status":"ok","timestamp":1669982272964,"user_tz":-60,"elapsed":312,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}}},"outputs":[],"source":["class CharLSTM(nn.Module):\n","\n","    def __init__(self, vocab_size, rnn_size, mlp_size):\n","        super().__init__()\n","        self.rnn_size = rnn_size\n","\n","        # TODO: Define the LSTM\n","        self.lstm = nn.LSTM(vocab_size, rnn_size, batch_first = True)\n","        self.dout = nn.Dropout(0.4)\n","\n","        # TODO: Create an MLP with a hidden layer of mlp_size neurons that maps\n","        # from the RNN hidden state space to the output space of vocab_size\n","        self.mlp = nn.Sequential(\n","          # Linear layer\n","          # Activation function\n","          # Dropout (0.4)\n","          # Linear layer\n","          # Activation function\n","          nn.Linear(rnn_size, mlp_size),\n","          nn.ReLU(),\n","          nn.Dropout(0.4),\n","          nn.Linear(mlp_size, vocab_size),\n","          nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, sentence, state=None):\n","        bsz, slen, vocab = sentence.shape\n","        ht, state = self.lstm(sentence, state)\n","        ht = self.dout(ht)\n","        h = ht.contiguous().view(-1, self.rnn_size)\n","        logprob = self.mlp(h)\n","        return logprob, state"]},{"cell_type":"markdown","metadata":{"id":"4K3L5BIyLrja"},"source":["Test how the model performs when using randomly initialized weights and biases:"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FnZ0Jar_lLot","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669982294070,"user_tz":-60,"elapsed":322,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"74f381e1-49b1-4f07-ab8a-af86048ef78b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Monica was NNNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","NNNN\n","\n"]}],"source":["# Let's build an example model and see what the scores are before training\n","model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n","\n","# This should output crap as it is not trained, so a fixed random tag for everything\n","\n","def gen_text(model, seed, char2idx, num_chars=150):\n","  model.eval()\n","  # Here we don't need to train, so the code is wrapped in torch.no_grad()\n","  with torch.no_grad():\n","      inputs = prepare_sequence(seed, char2idx)\n","      # fill the RNN memory with the seed sentence\n","      seed_pred, state = model(inputs.unsqueeze(0))\n","      # now begin looping with feedback char by char from the last prediction\n","      preds = seed\n","      curr_pred = torch.topk(seed_pred[-1, :], k=1, dim=0)[1]\n","      curr_pred = idx2char[curr_pred.item()]\n","      preds += curr_pred\n","      for t in range(num_chars):\n","        curr_pred, state = model(prepare_sequence(curr_pred, char2idx).unsqueeze(0), state)\n","        curr_pred = torch.topk(curr_pred[-1, :], k=1, dim=0)[1]\n","        curr_pred = idx2char[curr_pred.item()]\n","        if curr_pred == '$':\n","          # special token to add newline char\n","          preds += '\\n'\n","        else:\n","          preds += curr_pred\n","      return preds\n","\n","      \n","print(gen_text(model, 'Monica was ', char2idx))"]},{"cell_type":"markdown","metadata":{"id":"a_HuhKqRL0p-"},"source":["Prepare the training data by defining the data batches:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Uz6PM_vjlLou","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669982340651,"user_tz":-60,"elapsed":928,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"d0992af3-fc6f-4064-81d0-6b2cb2bf9b52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original training string len:  23149\n","Sub-sequences len:  361\n"]}],"source":["BATCH_SIZE = 64\n","T = len(training_data)\n","CHUNK_SIZE = T // BATCH_SIZE\n","# let's first chunk the huge train sequence into BATCH_SIZE sub-sequences\n","trainset = [training_data[beg_i:end_i] \\\n","            for beg_i, end_i in zip(range(0, T - CHUNK_SIZE, CHUNK_SIZE),\n","                                    range(CHUNK_SIZE, T, CHUNK_SIZE))]\n","print('Original training string len: ', T)\n","print('Sub-sequences len: ', CHUNK_SIZE)\n","\n","# The way training works is the following:\n","# at each batch sampling from the trainset,ence, each of the BATCH_SIZE sub-sequences\n","# in batch b[i] will continue in batch b[i + 1] in the same position of the batch dimension.\n","# This is called stateful sampling, where we train with consecutive windows of sequences\n","# We broke the long string into BATCH_SIZE subsequence, so we introduced BATCH_SIZE - 1 \n","# discontinuities... YES. But we can assume that each sub-sequence is continuous in a long\n","# enough chunk so that those discontinuities are negligible."]},{"cell_type":"markdown","metadata":{"id":"U_VVeGkjk5bs"},"source":["##### Exercise 4.4\n","\n","What is the length of the sliding window that will run over each of the training sub-sequences? \n","\n","NOTE: it is defined as a hyper-parameter above. How is this related to the backpropagation through time (BPTT)?"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"BjjCPxLGlLov","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1669983909383,"user_tz":-60,"elapsed":1544491,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"0c9f6eca-f9dd-4021-9d02-0552ebf271f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------\n","They was a like the sore shered the sing the with the wish the wish the wish the wish the wish the wish the wish the wish the wish the wish the wish the wis\n","------------------------------\n","Finished epoch 50 in 0.3 s: loss: 1.605563\n","------------------------------\n","They was Monica's geeky oldenters.]\n","Rachel: Well, maybe that's my decision. Wel, maybe I don't need your money. Wait!! Wait, I said I gonta weta  I just wan\n","------------------------------\n","Finished epoch 100 in 0.3 s: loss: 0.304356\n","------------------------------\n","They was no live himes like that? What? You any a shat dreat with and in it wo louds.\n","Phoebe: Oh, I just wall me liked of the cafeer to catch and Ross it ca\n","------------------------------\n","Finished epoch 150 in 0.3 s: loss: 0.053051\n","------------------------------\n","They was now you can Barry? I can't stop smiling.\n","Rachel: Oh, you was Fithing a bit change.]\n","Phoebe: (singing) Love is sweet as summbrink, purs. This is aul\n","------------------------------\n","Finished epoch 200 in 0.3 s: loss: 0.026850\n","------------------------------\n","They was Monica's geeky olded br akay. A just pus it like whing you found Jonn and Davidy the s, in whil Is iutto her wand I started wonder.]\n","Chandler: And \n","------------------------------\n","Finished epoch 250 in 0.3 s: loss: 0.017837\n","------------------------------\n","They was no you ready to just in roght word.\n","Monica: And who pays for the beft of your love, your love...is like a giant pime) I'll not man a job, (Rachel a\n","------------------------------\n","Finished epoch 300 in 0.3 s: loss: 0.014532\n","------------------------------\n","They was (They and cance for the back an hit is aul.\n","All: Hey! Paul! Hi! The Wine Guy! Hey!\n","Chandler: I was firet tats.\n","Paul: Yeah. (They kiss) Thank you. (\n","------------------------------\n","Finished epoch 350 in 0.3 s: loss: 0.017443\n","------------------------------\n","They was no stop in his is hopsen hin shat stops within any pining to the dents to she dart. Some Lonica: Stop!\n","Paul: No, I'm telling you last night you rea\n","------------------------------\n","Finished epoch 400 in 0.3 s: loss: 0.011724\n","------------------------------\n","They was no like the staing the how me, I'm gutsing marriel's, everyone is sitting around the kitchen table.\n","Rachel: Look Daddy, it's my life. Well maybe I'\n","------------------------------\n","Finished epoch 450 in 0.3 s: loss: 0.011393\n","------------------------------\n","They was no sing them.\n","Rachel: Um... my... father.\n","[Scene: Monica and Paul walk to the door and opens it to leave.)\n","Chandler: Al right, kids, I gotta get to\n","------------------------------\n","Finished epoch 500 in 0.3 s: loss: 0.011397\n","------------------------------\n","They was no live him s Riss the goom.)\n","Monica: See you make toing that weal in poushe be out. You canel anything, you can alays come to Joey. Me and Chandle\n","------------------------------\n","Finished epoch 550 in 0.3 s: loss: 0.009195\n","------------------------------\n","They was no stap in pround and tabted to canch the room.)\n","Chandler: And I just want a million dolars! (He extends his hand hopefully.)\n","Monica: So thop and t\n","------------------------------\n","Finished epoch 600 in 0.3 s: loss: 0.009509\n","------------------------------\n","They was no like whome to the counds.\n","Ross: (clutching a beer can a wet. Monica: Alerther-\n","Rachel: Oh God... well, it is realing live hig your for any dryou\n","------------------------------\n","Finished epoch 650 in 0.3 s: loss: 0.008930\n","------------------------------\n","They was no you dinn anytay do to at that bream.\n","Phoebe: No.\n","Chandler: All finished!\n","Ross: (clutching a beer can a pean. She some of a duffen a whone (Think\n","------------------------------\n","Finished epoch 700 in 0.3 s: loss: 0.010639\n","------------------------------\n","They was the started to ser change.]\n","Monica: Well, that's it (To Ros) You gonna crash on the couch?\n","Ross: No. No, I got a gota go ah, go ah...\n","Ross: A wande\n","------------------------------\n","Finished epoch 750 in 0.3 s: loss: 0.007407\n","------------------------------\n","They was not look it and a brolk it out, be the end of which shertable know wo woll's fivorice are you like bey.\n","Monica: (to Ros) Let me get you some coffee\n","------------------------------\n","Finished epoch 800 in 0.3 s: loss: 0.007381\n","------------------------------\n","They was no snap in his urtle for two years.\n","[Scene: Central Perk, everyone ks there is working as Frannica: I think we are getting a little ahead of selve \n","------------------------------\n","Finished epoch 850 in 0.3 s: loss: 0.004483\n","------------------------------\n","They was no snep in his up lithe be Head that credit for the bedry whill my beart. The whole, 'hat' thing.\n","Joey: (cometing her a wark.\n","Monica: You atually b\n","------------------------------\n","Finished epoch 900 in 0.3 s: loss: 0.008262\n","------------------------------\n","They was the bits and kinda but out, and that is why we don't do that grabbed my small intestine, pulled it ot my mouth and tied it around my neck...\n","Chandl\n","------------------------------\n","Finished epoch 950 in 0.3 s: loss: 0.008332\n","------------------------------\n","They was the book as Ross is not looking and they wes, everyone is sitting around the kitchen table.  Rachel's credit cards are spread out on the table  out\n","------------------------------\n","Finished epoch 1000 in 0.3 s: loss: 0.006721\n","------------------------------\n","They was no didn't know anybody. And I ended up living room and Comy Deday beat.\n","Rachel: Well, maybe that's my decision. Wel, maybe I don't need your money.\n","------------------------------\n","Finished epoch 1050 in 0.3 s: loss: 0.006370\n","------------------------------\n","They was not look it and real that out on the think God! I just wanta be morried again!\n","(Rachel enters in a wet wedding dress and starts to shere. And Monne\n","------------------------------\n","Finished epoch 1100 in 0.3 s: loss: 0.003604\n","------------------------------\n","They was Monica: See ya.... Waitwait, was I was I was I dot be cale to to went.\n","Monica: Wh'le you palks to the know and (pant dres to change.\n","Joey: (comorti\n","------------------------------\n","Finished epoch 1150 in 0.3 s: loss: 0.006432\n","------------------------------\n","They was the sidn the gook and they cheers't do this!\n","Monica: You can, I know you can!\n","Rachel: Want a wedding dress?   Hardly usedp okay? Talk to Barry? I c\n","------------------------------\n","Finished epoch 1200 in 0.3 s: loss: 0.006676\n","------------------------------\n","They was now live boy comere, and I had my and dodyou gon) Lous, Monica is was a lestion... (They al stare at him.) Did I say that out loud?\n","Ross: I thing t\n","------------------------------\n","Finished epoch 1250 in 0.3 s: loss: 0.004705\n","------------------------------\n","They was no you  auld to tou go I worl with Jut soud of a for the warch!\n","Rachel: What fer. And anything?\n","Joey: I doubt it. Mosly regional work.\n","Monica: Oh w\n","------------------------------\n","Finished epoch 1300 in 0.3 s: loss: 0.003779\n","------------------------------\n","They was not love hime sould.\n","(Monica gues to change.)\n","Phoebe: (singing) Love is sweet as summer showers, love is a wondrous work of art, but you just theng\n","------------------------------\n","Finished epoch 1350 in 0.3 s: loss: 0.005819\n","------------------------------\n","They was no sing thing snound the kitchen table.  And that ever happened to you! You got married, you canen can the how that you and I have kinda drifted ap\n","------------------------------\n","Finished epoch 1400 in 0.3 s: loss: 0.004988\n","------------------------------\n","They was now you? You gow a robled you be alays to to her wat I was a lesbian... (They al stare at him.) Did I say that out loud?\n","Ross: I thing we he- shat \n","------------------------------\n","Finished epoch 1450 in 0.3 s: loss: 0.003675\n","------------------------------\n","They was no snap in his ustle for the and they cheer 't comectica: The worlyou're looking for is 'Anyway'...\n","Monica: All right, c'mere, gimme your fet. (She\n","------------------------------\n","Finished epoch 1500 in 0.3 s: loss: 0.003797\n","------------------------------\n","They was no snap in his urtle for two years.\n","[Scene: Central Perk, everyone is there.]\n","Joey: (sitting on the arm of alaughed and the this guy with a big ham\n","------------------------------\n","Finished epoch 1550 in 0.3 s: loss: 0.003133\n","------------------------------\n","They was gory! (They are starts to she down the stairs! Push her down the stairs!\n","(She gors the firng time.\n","Rachel: Thank you.\n","Phoebe: You me nover have gra\n","------------------------------\n","Finished epoch 1600 in 0.3 s: loss: 0.005084\n","------------------------------\n","They was got a job?\n","Rachel: Are you kidding? I'm trained you wand you love dize you love if your life.  The whole, 'hat' thing.\n","Joey: (comorting her) And he\n","------------------------------\n","Finished epoch 1650 in 0.3 s: loss: 0.003898\n","------------------------------\n","They was no snap in his washe looking at this gravy boat. This really necessary?  I mean, I have you drank it out of the can, I should have known.\n","Joey: Hey\n","------------------------------\n","Finished epoch 1700 in 0.3 s: loss: 0.003572\n","------------------------------\n","They was goly and they weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it welve somer and over and over again until it\n","------------------------------\n","Finished epoch 1750 in 0.3 s: loss: 0.002971\n","------------------------------\n","They was no snap in his was hele with Monica.\n","Monica: Well, I am to gotta be achell, I'm sorry. I didn't canch your name. Paul, was it doe the others can't \n","------------------------------\n","Finished epoch 1800 in 0.3 s: loss: 0.004650\n","------------------------------\n","They was niles, you got a job?\n","Rachel: Are you kidding? I'm trained you was Fintle and you're having sex!  So? Who?\n","Monica: Now I'm guesing that he bought h\n","------------------------------\n","Finished epoch 1850 in 0.3 s: loss: 0.003690\n","------------------------------\n","They was only one woman- for her...\n","Joey: What what?  There ald not that hysterical phone.\n","Monica: Oh wait, wait, unless you happened to catch the Reruns' p\n","------------------------------\n","Finished epoch 1900 in 0.3 s: loss: 0.005075\n","------------------------------\n","They was no like mes. You're get ing that he's gotta be something wrong with him!\n","Chandler: All right Joey, be nice.  So does he have hought be toway.\n","Paul:\n","------------------------------\n","Finished epoch 1950 in 0.3 s: loss: 0.002607\n","------------------------------\n","They was no coml in so enting and room.)\n","Monica: (explaining to the others) Carol mome Morcand you re any hink to be incredibly lucky to become Mrs. Barry l\n","------------------------------\n","Finished epoch 2000 in 0.3 s: loss: 0.004846\n","------------------------------\n","They was Monica's geeky older brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you hand- It's June.  I'm outta here. (Exits.)\n","Ross: Y'know, I figure if I can ma\n","------------------------------\n","Finished epoch 2050 in 0.3 s: loss: 0.002770\n","------------------------------\n","They was no snap in his up le for two years.\n","[Scene: Central Perk, everyone is there.]\n","Joey: (sitting on the arm of a were. (The sor something and noodles w\n","------------------------------\n","Finished epoch 2100 in 0.3 s: loss: 0.003042\n","------------------------------\n","They was Monica's geeky olde, I was looking at this gravy boat. This really not starts looking at me.\n","Monica: You be okay?\n","Ross: Y'know, I figure if I can m\n","------------------------------\n","Finished epoch 2150 in 0.3 s: loss: 0.002225\n","------------------------------\n","They was no snap in his urtle for two years.\n","[Scene: Central Perk, everyone is sitting around the kitchen table.\n","Rachel: Look Daddy, it's my life. Well mayb\n","------------------------------\n","Finished epoch 2200 in 0.3 s: loss: 0.003380\n","------------------------------\n","They was no snap in his it so that her and watching a Spanish Soap on TV and are trying there and I candlertly and thene the ull you four your parachute?\"  \n","------------------------------\n","Finished epoch 2250 in 0.3 s: loss: 0.004170\n","------------------------------\n","They was not lave in!  The whole, 'hat' thing.\n","Joey: (comething him and watching Joanne Loves Chaci.]\n","Press: (Exitsing out here.\n","Joey: (sitting on the arm o\n","------------------------------\n","Finished epoch 2300 in 0.3 s: loss: 0.002603\n","------------------------------\n","They was no start with the coffee, grimace, and pour it into sentart.]\n","Monica: (spitting out of the wandow.)\n","[Cut to Rachel starts to sher cut. Chandler: (S\n","------------------------------\n","Finished epoch 2350 in 0.3 s: loss: 0.002578\n","------------------------------\n","They was no started hon er say her-\n","Monica: -leg?\n","Paul: (laughing) That's the didn't can't believe you didn't know it was a line!\n","Monica: Why?! Why, why wou\n","------------------------------\n","Finished epoch 2400 in 0.3 s: loss: 0.002425\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you go tra here.\n","Chandler: It's a beautiful thing that we tome.\n","(They and Chandler\n","------------------------------\n","Finished epoch 2450 in 0.3 s: loss: 0.003294\n","------------------------------\n","They was no can I know that do and that is and who am I doing this for?'. (to Monica: Stop!\n","Paul: No, I'm telling you last night be here know four love of c\n","------------------------------\n","Finished epoch 2500 in 0.3 s: loss: 0.003654\n","------------------------------\n","They was no live hims celling winds he watch!\n","Joey: C'mon, you're going out with the goove Love is sight what a lith the bookcase!\n","Chandler: Al right, kids,\n","------------------------------\n","Finished epoch 2550 in 0.3 s: loss: 0.003013\n","------------------------------\n","They was no you're having sex!  So? Who?\n","Monica: How do you do that?\n","Frannie: Hey, Monica!\n","Monica: Hey Frannie, and you are whating a little ahead of selver\n","------------------------------\n","Finished epoch 2600 in 0.3 s: loss: 0.002063\n","------------------------------\n","They was no live hime seelly in thing theme little wormen you can't live off your parents your whole life.\n","Ross: A don't want to be single, okay? just... I \n","------------------------------\n","Finished epoch 2650 in 0.3 s: loss: 0.001599\n","------------------------------\n","They was no like a hem- Dow do you think it was a just probably not what you need right now, but you just plought I was Monica's geeky olde brother.\n","Rachel:\n","------------------------------\n","Finished epoch 2700 in 0.3 s: loss: 0.004265\n","------------------------------\n","They was no like a symbolic gesture...\n","Monica: I know, he's just so, cut, cut, cut, cut, cut..\n","Chandler: (as Rachel is there.]\n","Joey: (sitting on the arm of \n","------------------------------\n","Finished epoch 2750 in 0.3 s: loss: 0.002975\n","------------------------------\n","They was nowever back. And that I was more turned on by this amazing? I mean, I had you need anything, you can alays come to Joey. Me and Chandler live acro\n","------------------------------\n","Finished epoch 2800 in 0.3 s: loss: 0.001848\n","------------------------------\n","They weren't there and then here she widl Guy!\n","Ross: I wandring a little ahead of selver here. Okay. Okay. I am just going to get up, go th work Joey: De-y.\n","------------------------------\n","Finished epoch 2850 in 0.3 s: loss: 0.002784\n","------------------------------\n","They well my aure! No, I'm not ready!  Hey, Paul!\n","Paul: Yeah?\n","Joey: Here's a little ahead of selver here. Okay. Okay. I am just going to get up, go o work a\n","------------------------------\n","Finished epoch 2900 in 0.3 s: loss: 0.002427\n","------------------------------\n","They was no snap in his ustle for two years.\n","[Scene: Central Perk, everyone is there and whet is with Paul the Wine Guy?\n","Ross: I just grabbed a spoon. (Roes\n","------------------------------\n","Finished epoch 2950 in 0.3 s: loss: 0.002355\n","------------------------------\n","They was no snap in his fint ou goon.\n","Joey: (cooksting her) And hey, you need anything, you can al have you something, Ross. There's lots of flavor on the w\n","------------------------------\n","Finished epoch 3000 in 0.3 s: loss: 0.003276\n","------------------------------\n","They was no know that you and I have kinda drifted apart, but out, and that's when it hit me: how much Barry loks like Mr. Potato Head. Y'know, I mean, I al\n","------------------------------\n","Finished epoch 3050 in 0.3 s: loss: 0.007128\n","------------------------------\n","They was no like a hat this asazing? I mean, I have you. momething alound my neck...\n","Chandler: Al right, kids, I gotta get to work. If I don't inpu those nu\n","------------------------------\n","Finished epoch 3100 in 0.3 s: loss: 0.000956\n","------------------------------\n","They was the starts to shark.\n","Joey: Look, So you here welcome. I remember when I first came to this ity. I was fourteen. My mom had just killed herself, and\n","------------------------------\n","Finished epoch 3150 in 0.3 s: loss: 0.001486\n","------------------------------\n","They was the book atat her ableftonight, Joey and Chandler are coming over to hep me put together my new furniture.\n","Chandler: (deapsnge]\n","Chandler: Alright, \n","------------------------------\n","Finished epoch 3200 in 0.3 s: loss: 0.002671\n","------------------------------\n","They was the and reading scenting want he wouldn't be an isse... [Scene: Monica's Apartment, everyone is there.]\n","Joey: (sitting on the arm of a wedn't there\n","------------------------------\n","Finished epoch 3250 in 0.3 s: loss: 0.007112\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you think about him all day. Or else I'm just gonna help?\n","Phoebe: You wanna help?\n","\n","------------------------------\n","Finished epoch 3300 in 0.3 s: loss: 0.001639\n","------------------------------\n","They was the big that he's a dead man.  Oh, Chandler? (Starts after drank it out of the can, I should have known.\n","(Monica stomps on Paul's watch and goes wh\n","------------------------------\n","Finished epoch 3350 in 0.3 s: loss: 0.007736\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you want me to stay?\n","Ross: (choked voice) That'd be good...\n","Monica: (horrified) Re\n","------------------------------\n","Finished epoch 3400 in 0.3 s: loss: 0.001414\n","------------------------------\n","They was the bignt and was it wos a line (Monica pushes him off of the sofa as Rachel enters in a wet wedding dress and starts to she kitchen and says to Ch\n","------------------------------\n","Finished epoch 3450 in 0.3 s: loss: 0.003589\n","------------------------------\n","They was the bignt now that he's a dead man.  Oh, Chandler? (Starts afters and rindler, and she dadn't know, how should I know?\n","Chandler: She sings)\n","Rachel:\n","------------------------------\n","Finished epoch 3500 in 0.3 s: loss: 0.002952\n","------------------------------\n","They was the book at her.) bluebells and- something with mittens... La la la...something and noodles with string.  These and they where's a litile bround th\n","------------------------------\n","Finished epoch 3550 in 0.3 s: loss: 0.000531\n","------------------------------\n","They well not look at her.) bluebells and- something with mittens... La la a lo...sex.\n","[Scene: Ross's Apartment, they're all sitting to the don't wand her w\n","------------------------------\n","Finished epoch 3600 in 0.3 s: loss: 0.003025\n","------------------------------\n","They was no snap in his like that.)\n","Chandler: (as Rachel inters in Proubhe, drink it, or not to let my intense vulnerability porten!\n","Joey: Which goes where?\n","------------------------------\n","Finished epoch 3650 in 0.3 s: loss: 0.001232\n","------------------------------\n","They welcome back! How was Florida?\n","Frannie: You had sex!  So With Monica: Okay, umm-umm, I'll just--I'll be right back in high school, I had a, um, major c\n","------------------------------\n","Finished epoch 3700 in 0.3 s: loss: 0.002518\n","------------------------------\n","They was the book at her.) bluebells and- something with mittens... La la la...something and noodles with string.  These and Chandler are coming over to her\n","------------------------------\n","Finished epoch 3750 in 0.3 s: loss: 0.002482\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you know me...\n","Rachel: They're my new 'I don't want her to go through what I was m\n","------------------------------\n","Finished epoch 3800 in 0.3 s: loss: 0.001814\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you want you to buy me a hat, I'm saying I am a ha- It's a beautiful thing a Sexpi\n","------------------------------\n","Finished epoch 3850 in 0.3 s: loss: 0.000981\n","------------------------------\n","They well not take this abus of her drink.) ...Sexually.\n","Monica: (spitting out work of art, but you just panted and I said, 'What if I wanna be a- a proned.\n","------------------------------\n","Finished epoch 3900 in 0.3 s: loss: 0.001034\n","------------------------------\n","They was Monica's geeky olde brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you have mome sort of beacon the coffe!  The can cands like a down to be here.\n","[Sc\n","------------------------------\n","Finished epoch 3950 in 0.3 s: loss: 0.001165\n","------------------------------\n","They was Monica's geeky older brother.\n","Rachel: I did.\n","Ross: Oh. Listen, do you have more sow Paul?\n","Frannie: Are you kidding? I take credit for the best what\n","------------------------------\n","Finished epoch 4000 in 0.3 s: loss: 0.006486\n","------------------------------\n","They was no Hive boy. Oh you really fight the here.)\n","Monica: So how you doing today? Did you get?\n","Ross: You guys.\n","Chandler: Oh, how well you know me...\n","Rach\n","------------------------------\n","Finished epoch 4050 in 0.3 s: loss: 0.002873\n","------------------------------\n","They was no sing that he bought her the big pipe organ, and shairs! Paul the Wine Guy?\n","Ross: I just grabbed a spoon. (Roes and Rachel: There's Paul's wastin\n","------------------------------\n","Finished epoch 4100 in 0.3 s: loss: 0.001525\n","------------------------------\n","They was only one woman- for her...\n","Joey: What that dream.\n","Phoebe: No.\n","Chandler: All finished!\n","Ross: (clutching a beer can a be realing scang on the goong) \n","------------------------------\n","Finished epoch 4150 in 0.3 s: loss: 0.001478\n","------------------------------\n","They well.\n","Monica: Oh really, so that hysterical phone.\n","Monica: What?..... What, you wanna spell it out with the gooncand Monica enters the living room as R\n","------------------------------\n","Finished epoch 4200 in 0.3 s: loss: 0.001487\n","------------------------------\n","They was no ding.\n","Paul: (entering. Good mern....\n","Rachel: So, like, you guys all have jobs?\n","Rachel: Are you kidding? I'm trained you me and that is au nta We\n","------------------------------\n","Finished epoch 4250 in 0.3 s: loss: 0.001054\n","------------------------------\n","They was no snap in his urtle for two years.\n","[Scene: Central Perk, everyone is there.]\n","Joey: (sitting on the arm of these little worm guys. I have no backet\n","------------------------------\n","Finished epoch 4300 in 0.3 s: loss: 0.002036\n","------------------------------\n","They was of your broakcas Rachel!  That was a library card!\n","All: Cut, cut, cut, cut, cut, cut, cut..\n","Chandler: (as Rachel is there.]\n","Joey: (sitting on the a\n","------------------------------\n","Finished epoch 4350 in 0.3 s: loss: 0.001930\n","------------------------------\n","They wey now do n can!  Buzz him in!\n","Joey: Who's Paul?\n","Ross: Paul the Wine Guy? Oh yeah, I know Paul.\n","Monica: You mean you know Paul like that. With feeling\n","------------------------------\n","Finished epoch 4400 in 0.3 s: loss: 0.001362\n","------------------------------\n","They was only one woman- for her...\n","Joey: What really necessary?  I mean, I have any idea who me is right now, but you just thought I was Monica's geeky old\n","------------------------------\n","Finished epoch 4450 in 0.3 s: loss: 0.001472\n","------------------------------\n","They was only one woman- for her...\n","Joey: What realy gorgeous Lamauge gravy boat. When all of a sudden, the phone starts to ring. Now I don't want to be sin\n","------------------------------\n","Finished epoch 4500 in 0.3 s: loss: 0.000786\n","------------------------------\n","They was no didn't know anybody. And I ended up living it what's with you?\n","Ross: I just grabbed a spoon. (Ro s) Oh one woman- for her...\n","Joey: What was what\n","------------------------------\n","Finished epoch 4550 in 0.3 s: loss: 0.001773\n","------------------------------\n","They was no dinn't favorite bath maybe I don't need your money. Wait!! Wait, I say maybe!!\n","[Time Lapse, Rachel is breating into a plant pot.) Although actua\n","------------------------------\n","Finished epoch 4600 in 0.3 s: loss: 0.001777\n","------------------------------\n","They was only one woman- for her...\n","Joey: What that dream.\n","Phoebe: No.\n","Chandler: All finished!\n","Ross: (clutching a beer can a pand.\n","Joey: Look, Ross, you got\n","------------------------------\n","Finished epoch 4650 in 0.3 s: loss: 0.001829\n","------------------------------\n","They was only one woman- for her...\n","Joey: What that dream.\n","Phoebe: No.\n","Chandler: All finished!\n","Ross: (clutching a beer can a pasned you aud I have kinda dri\n","------------------------------\n","Finished epoch 4700 in 0.3 s: loss: 0.001856\n","------------------------------\n","They was only one woman- for her...\n","Joey: What what if you get a lithere was no snap in his right. [Scene: Monica's Apartment, Rachel is talking and the kit\n","------------------------------\n","Finished epoch 4750 in 0.3 s: loss: 0.001360\n","------------------------------\n","They was of like you gotta how we'll be very happy.\n","Monica: No I don't, to hell with her, she not me. [Time Lapse]\n","Chandler: Alright, kids, I gotta get to w\n","------------------------------\n","Finished epoch 4800 in 0.3 s: loss: 0.002371\n","------------------------------\n","They can't do.\n","Chandler: If can invade Pole o, there's a knock on the door and it's Paul.)\n","Monica: Hi, I gotsa go that right? Welcome back to the world 'Bil\n","------------------------------\n","Finished epoch 4850 in 0.3 s: loss: 0.001927\n","------------------------------\n","They was of your live, your love...is like a giant pien...crapping on my heart.  La-la-la-la-la- (something wand with she redipl back in high school, I had \n","------------------------------\n","Finished epoch 4900 in 0.3 s: loss: 0.001802\n","------------------------------\n","They was ofly do think you re a siget.\n","Monica: Oh wait, wait, unless you just lingld upbeat for the bestart.\n","Joey: That wasn't a real date?! What the hell d\n","------------------------------\n","Finished epoch 4950 in 0.3 s: loss: 0.002669\n","------------------------------\n","They was no dinn't know this, bus a lint doen't know anybody. And I ended up living over to her stuff out today.\n","Joey: Ohh.\n","Monica: (to Ros) Let me get you \n","------------------------------\n","Finished epoch 5000 in 0.3 s: loss: 0.001285\n"]},{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'NLLLoss')"]},"metadata":{},"execution_count":21},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Let's now build a model to train with its optimizer and loss\n","model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n","model.to(device)\n","loss_function = nn.NLLLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","NUM_EPOCHS = 5000\n","tr_loss = []\n","state = None\n","timer_beg = timer()\n","for epoch in range(NUM_EPOCHS):\n","  model.train()\n","  # let's slide over our dataset\n","  for beg_t, end_t in zip(range(0, CHUNK_SIZE - SEQ_LEN - 1, SEQ_LEN + 1),\n","                          range(SEQ_LEN + 1, CHUNK_SIZE, SEQ_LEN + 1)):\n","    # Step 1. Remember that Pytorch accumulates gradients.\n","    # We need to clear them out before each instance\n","    optimizer.zero_grad()\n","\n","    dataX = []\n","    dataY = []\n","    # Step 2. Get our inputs ready for the network, that is, turn them into\n","    # Tensors of one-hot sequences. \n","    for sent in trainset:\n","      # chunk the sentence\n","      chunk = sent[beg_t:end_t]\n","      # get X and Y with a shift of 1\n","      X = chunk[:-1]\n","      Y = chunk[1:]\n","      # convert each sequence to one-hots and labels respectively\n","      X = prepare_sequence(X, char2idx)\n","      Y = prepare_sequence(Y, char2idx, onehot=False)\n","      dataX.append(X.unsqueeze(0)) # create batch-dim\n","      dataY.append(Y.unsqueeze(0)) # create batch-dim\n","    dataX = torch.cat(dataX, dim=0).to(device)\n","    dataY = torch.cat(dataY, dim=0).to(device)\n","\n","    # Step 3. Run our forward pass.\n","    # Forward through model and carry the previous state forward in time (statefulness)\n","    y_, state = model(dataX, state)\n","    # detach the previous state graph to not backprop gradients further than the BPTT span\n","    state = (state[0].detach(), # detach c[t]\n","             state[1].detach()) # detach h[t]\n","\n","    # Step 4. Compute the loss, gradients, and update the parameters by\n","    #  calling optimizer.step()\n","    loss = loss_function(y_, dataY.view(-1))\n","    loss.backward()\n","    optimizer.step()\n","    tr_loss.append(loss.item())\n","  timer_end = timer()  \n","  if (epoch + 1) % 50 == 0:\n","    # Generate a seed sentence to play around\n","    model.to('cpu')\n","    print('-' * 30) \n","    print(gen_text(model, 'They ', char2idx))\n","    print('-' * 30)\n","    model.to(device)\n","    print('Finished epoch {} in {:.1f} s: loss: {:.6f}'.format(epoch + 1, \n","                                                               timer_end - timer_beg,\n","                                                               np.mean(tr_loss[-10:])))\n","  timer_beg = timer()\n","\n","plt.plot(tr_loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('NLLLoss')"]},{"cell_type":"markdown","metadata":{"id":"Iulcm9gPNhwK"},"source":["Now that the generator of characters is trained, we can ask it to predict the rest of a sentence that begins with `Professor `:"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"2HvrKaSflLow","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669984641593,"user_tz":-60,"elapsed":2437,"user":{"displayName":"Gerard Comas Quiles","userId":"07283243575389952521"}},"outputId":"3ba57c85-086c-43d8-f5d6-37e8506f199e"},"outputs":[{"output_type":"stream","name":"stdout","text":["I was sitting ma little wheater in the park.\n","Joey: Look, would I just be a re sow you miget you reany that is you get and thes is hand the tois guy with a big hammer said you might be here sow Paul?\n","Frannie: Are you kidding? I take credit for you. Leverybody really not that you need right now, he's such a mess with ghe bookcase here to go through what I was a lot?\n","Rachel: Are you kidding? I'm trained your money. Wait!! Wait, I say in the door and it's Paul.)\n","Monica: Hi, om and roodles with her, she pidnen and waithout with a bea- Lous, in the rould workeru... I have any idea who me is right now, but you just beouten and that's it? Unfortunately in my cas, there was only one woman- for her...\n","Joey: What for?\n","Rachel: I'm gonna get up of a dound on body whit you feed here sow Paul?\n","Frannie: Are you kidding? I take credit for you. Leverybody really not that you need right now, he's such a mess with ghe bookcase here to go through what I was a lot?\n","Rachel: Are you kidding? I'm trained your money. Wait!! W\n"]}],"source":["print(gen_text(model.to('cpu'), 'I was sitting ', char2idx, 1000))"]},{"cell_type":"markdown","metadata":{"id":"lVRsFgHZa3f3"},"source":["### References\n","\n","[1] https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"]}],"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3.7.10 ('trading')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.10"},"vscode":{"interpreter":{"hash":"148c72a8fa8931f1b4adec61e5c626da15d84fdba20a1a50eaf0317d3b0337d5"}},"colab":{"provenance":[{"file_id":"https://github.com/telecombcn-dl/labs-all/blob/main/labs/rnn/lab_rnn_todo.ipynb","timestamp":1669980329593}]}},"nbformat":4,"nbformat_minor":0}