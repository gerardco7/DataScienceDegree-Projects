{"cells":[{"cell_type":"markdown","metadata":{"id":"F6Jv3yx4SU3F"},"source":["# CAI Lab Session 2: Intro to ElasticSearch"]},{"cell_type":"markdown","metadata":{"id":"Ree4dB0LSU3N"},"source":["In this session you will learn:\n","\n","- a few basics of the `ElasticSearch` database\n","- how to index a set of documents and how to ask simple queries about these documents\n","- how to do this from `Python`\n","- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"]},{"cell_type":"markdown","metadata":{"id":"6y20iRGVSU3P"},"source":["## 1. ElasticSearch\n","\n","[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n","\n","| Relational DB | ElasticSearch |\n","|---|---|\n","| Database | Index |\n","| Table | Type |\n","| Row / record | Document |\n","| Column | Field |\n","\n","An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n","\n","`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n","\n","- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n","- Intros you may want to have a look at:\n","    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n","    - http://joelabrahamsson.com/elasticsearch-101\n","- You found another one that you liked? Let us know."]},{"cell_type":"markdown","metadata":{"id":"7Pu0bRrjSU3Q"},"source":["## 2. Running ElasticSearch\n","\n","First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n","\n","This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n","\n","```\n","$ <path_to_elasticsearch_bin>/elasticsearch &\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EWuigDPYSU3S"},"source":["After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFpxHW0oSU3V"},"outputs":[],"source":["from pprint import pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efTLclHVSU3a","outputId":"ef18fb37-178b-4eb8-a247-d00781514a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["(b'{\\n  \"name\" : \"10-192-2-70client.eduroam.upc.edu\",\\n  \"cluster_name\" : \"el'\n"," b'asticsearch\",\\n  \"cluster_uuid\" : \"kJEWqbK9Q0CyycBbKYd1RQ\",\\n  \"version\" :'\n"," b' {\\n    \"number\" : \"8.10.0\",\\n    \"build_flavor\" : \"default\",\\n    \"build_t'\n"," b'ype\" : \"tar\",\\n    \"build_hash\" : \"e338da74c79465dfdc204971e600342b0aa87b'\n"," b'6b\",\\n    \"build_date\" : \"2023-09-07T08:16:21.960703010Z\",\\n    \"build_sna'\n"," b'pshot\" : false,\\n    \"lucene_version\" : \"9.7.0\",\\n    \"minimum_wire_compat'\n"," b'ibility_version\" : \"7.17.0\",\\n    \"minimum_index_compatibility_version\" :'\n"," b' \"7.0.0\"\\n  },\\n  \"tagline\" : \"You Know, for Search\"\\n}\\n')\n"]}],"source":["import requests\n","\n","try:\n","    resp = requests.get('http://localhost:9200/')\n","    pprint(resp.content)\n","\n","except Exception:\n","    print('elasticsearch is not running')"]},{"cell_type":"markdown","metadata":{"id":"skr8xHN2SU3e"},"source":["If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n","\n","**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n","\n","Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."]},{"cell_type":"markdown","metadata":{"id":"bWNxeW5JSU3f"},"source":["## 3. Indexing and querying\n","\n","`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match.\n","\n","These kinds of databases are behind search engines like Google Search or Bing.\n","\n","There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n","\n","We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4p7WNyKRSU3g","outputId":"e74e6513-8452-4aa4-acc7-a3d580c4c962"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting elasticsearch\n","  Obtaining dependency information for elasticsearch from https://files.pythonhosted.org/packages/bb/06/81b1d71ba0567ff39d0f98f3637e810846df92f6733aee46004a194b51ea/elasticsearch-8.9.0-py3-none-any.whl.metadata\n","  Downloading elasticsearch-8.9.0-py3-none-any.whl.metadata (5.2 kB)\n","Collecting elastic-transport<9,>=8 (from elasticsearch)\n","  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting urllib3<2,>=1.26.2 (from elastic-transport<9,>=8->elasticsearch)\n","  Obtaining dependency information for urllib3<2,>=1.26.2 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n","  Downloading urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n","Downloading elasticsearch-8.9.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: urllib3, elastic-transport, elasticsearch\n","Successfully installed elastic-transport-8.4.0 elasticsearch-8.9.0 urllib3-1.26.16\n","Collecting elasticsearch-dsl\n","  Obtaining dependency information for elasticsearch-dsl from https://files.pythonhosted.org/packages/92/4f/8966141ca545147b59d5869daa7a9bce34fb8f4a9ebd1d38cd23ba907a6f/elasticsearch_dsl-8.9.0-py3-none-any.whl.metadata\n","  Downloading elasticsearch_dsl-8.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: python-dateutil in /Users/lauragarcialopez/Library/Python/3.10/lib/python/site-packages (from elasticsearch-dsl) (2.8.2)\n","Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in /Users/lauragarcialopez/Library/Python/3.10/lib/python/site-packages (from elasticsearch-dsl) (8.9.0)\n","Requirement already satisfied: elastic-transport<9,>=8 in /Users/lauragarcialopez/Library/Python/3.10/lib/python/site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /Users/lauragarcialopez/Library/Python/3.10/lib/python/site-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n","Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/lauragarcialopez/Library/Python/3.10/lib/python/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (1.26.16)\n","Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2023.7.22)\n","Downloading elasticsearch_dsl-8.9.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: elasticsearch-dsl\n","Successfully installed elasticsearch-dsl-8.9.0\n"]}],"source":["!pip3 install elasticsearch --user\n","!pip3 install elasticsearch-dsl --user"]},{"cell_type":"markdown","metadata":{"id":"KTZB8x2ISU3h"},"source":["We are only going to see the essential elements for developing the session but feel free to learn more."]},{"cell_type":"markdown","metadata":{"id":"Vv52wdTsSU3h"},"source":["To interact with ElasticSearch with need a client object of type `Elasticsearch`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-c8EzWhpSU3h"},"outputs":[],"source":["from elasticsearch import Elasticsearch\n","\n","client = Elasticsearch(\"http://localhost:9200\")"]},{"cell_type":"markdown","metadata":{"id":"VCkpwY5vSU3h"},"source":["With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrk4pEkwSU3i"},"outputs":[],"source":["from elasticsearch_dsl import Index\n","\n","index = Index('test', using=client)"]},{"cell_type":"markdown","metadata":{"id":"QwSeVHcsSU3i"},"source":["First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ai7kKuHwSU3i","outputId":"6d010022-942c-4b67-939c-c6aed4c407a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting lorem\n","  Downloading lorem-0.1.1-py3-none-any.whl (5.0 kB)\n","Installing collected packages: lorem\n","Successfully installed lorem-0.1.1\n"]}],"source":["!pip3 install lorem --user  # Restart the kernel if you are not able to import the library in the next cell"]},{"cell_type":"markdown","metadata":{"id":"Yw_3Pi0FSU3j"},"source":["Now we create some random paragraphs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Lzd12ygSU3k","outputId":"55995e72-ab4b-43e7-e7d4-766e65191322"},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n","Aliquam tempora quisquam non dolore velit. Magnam sed modi neque adipisci consectetur modi consectetur. Neque eius amet modi velit amet ipsum voluptatem. Sit neque ipsum neque ut. Aliquam quiquia quiquia eius etincidunt dolorem consectetur. Adipisci eius voluptatem amet tempora.\n"]}],"source":["import lorem\n","\n","texts = [lorem.paragraph() for _ in range(10)]\n","print(len(texts))\n","print(texts[0])"]},{"cell_type":"markdown","metadata":{"id":"bMQDha8KSU3k"},"source":["Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `body` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBzBEkmkSU3k","outputId":"c3fa998b-63a4-4d4a-9f40-222877c28cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Indexing new text: Aliquam tempora quisquam non dolore velit. Magnam sed modi neque adipi ...\n","Indexing new text: Velit non adipisci sed etincidunt. Ipsum porro eius ipsum non dolorem  ...\n","Indexing new text: Porro sit neque modi consectetur tempora quaerat dolor. Quisquam numqu ...\n","Indexing new text: Dolore amet porro quiquia numquam. Quisquam quisquam labore sit quaera ...\n","Indexing new text: Amet ipsum numquam est sit etincidunt quiquia. Quisquam ut tempora qui ...\n","Indexing new text: Sit porro non voluptatem non. Modi etincidunt ut modi tempora. Aliquam ...\n","Indexing new text: Ipsum dolor etincidunt velit amet sit ut non. Quaerat quaerat dolore s ...\n","Indexing new text: Velit quaerat voluptatem ipsum quaerat ipsum neque. Etincidunt dolore  ...\n","Indexing new text: Dolorem ut adipisci magnam aliquam sed. Voluptatem quiquia porro dolor ...\n","Indexing new text: Adipisci labore dolore magnam quisquam ipsum. Velit consectetur magnam ...\n"]}],"source":["for t in texts:\n","    client.index(index='test', document={'text': t})\n","    print(f'Indexing new text: {t[:70]} ...')"]},{"cell_type":"markdown","metadata":{"id":"Pi7UNpRKSU3l"},"source":["In case we want to get all docs in the index, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmGROfQASU3l","outputId":"38edb9dc-aae7-431a-9ccc-51cad5e66dc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Got 10 hits:\n","{'text': 'Aliquam tempora quisquam non dolore velit. Magnam sed modi neque '\n","         'adipisci consectetur modi consectetur. Neque eius amet modi velit '\n","         'amet ipsum voluptatem. Sit neque ipsum neque ut. Aliquam quiquia '\n","         'quiquia eius etincidunt dolorem consectetur. Adipisci eius '\n","         'voluptatem amet tempora.'}\n","{'text': 'Velit non adipisci sed etincidunt. Ipsum porro eius ipsum non '\n","         'dolorem aliquam amet. Etincidunt magnam consectetur numquam magnam '\n","         'ut labore etincidunt. Magnam quisquam numquam non. Quisquam ut '\n","         'labore non est est. Sit modi quaerat ut quisquam.'}\n","{'text': 'Porro sit neque modi consectetur tempora quaerat dolor. Quisquam '\n","         'numquam aliquam dolorem amet magnam ut. Dolore quiquia quiquia '\n","         'etincidunt etincidunt magnam quiquia ut. Voluptatem amet ut sed. '\n","         'Labore quiquia magnam sit. Ut sed magnam tempora. Non est velit eius '\n","         'labore. Aliquam non dolorem ipsum modi adipisci sed etincidunt.'}\n","{'text': 'Dolore amet porro quiquia numquam. Quisquam quisquam labore sit '\n","         'quaerat labore. Dolore est aliquam magnam velit sed. Porro dolorem '\n","         'sit velit voluptatem adipisci ut amet. Porro dolorem dolor neque sit '\n","         'quiquia. Dolorem sed dolore labore voluptatem dolorem modi. Numquam '\n","         'consectetur non porro non quiquia ipsum porro. Labore voluptatem '\n","         'quisquam ipsum amet velit ipsum.'}\n","{'text': 'Amet ipsum numquam est sit etincidunt quiquia. Quisquam ut tempora '\n","         'quisquam tempora neque. Modi eius non dolore voluptatem sed ipsum '\n","         'consectetur. Quiquia adipisci sit quiquia tempora sed quaerat. Non '\n","         'adipisci dolore voluptatem ipsum sed dolor dolorem. Porro quisquam '\n","         'quisquam sed magnam dolorem voluptatem. Neque modi ipsum magnam '\n","         'consectetur labore numquam.'}\n","{'text': 'Sit porro non voluptatem non. Modi etincidunt ut modi tempora. '\n","         'Aliquam quisquam aliquam dolor dolore dolor modi numquam. Aliquam '\n","         'quisquam magnam modi dolorem dolor quaerat. Velit sit adipisci '\n","         'etincidunt modi.'}\n","{'text': 'Ipsum dolor etincidunt velit amet sit ut non. Quaerat quaerat dolore '\n","         'sed. Magnam magnam consectetur magnam voluptatem numquam. Voluptatem '\n","         'sed velit ut neque. Eius aliquam amet numquam sed amet magnam. '\n","         'Numquam labore sit adipisci aliquam ipsum.'}\n","{'text': 'Velit quaerat voluptatem ipsum quaerat ipsum neque. Etincidunt '\n","         'dolore sit ut amet quisquam. Ipsum quisquam dolore consectetur. Non '\n","         'etincidunt magnam quisquam. Ut aliquam numquam modi aliquam sed '\n","         'dolore modi. Amet labore est numquam. Sed non etincidunt eius. '\n","         'Quisquam neque neque modi voluptatem eius. Est magnam ut aliquam '\n","         'dolorem neque aliquam dolorem.'}\n","{'text': 'Dolorem ut adipisci magnam aliquam sed. Voluptatem quiquia porro '\n","         'dolore est numquam. Sit quiquia amet magnam sed etincidunt '\n","         'voluptatem. Adipisci quiquia dolor consectetur est eius porro. '\n","         'Labore dolore velit numquam. Eius ipsum neque adipisci quaerat eius. '\n","         'Sed ut non est est labore. Tempora adipisci etincidunt ipsum ut '\n","         'voluptatem sit.'}\n","{'text': 'Adipisci labore dolore magnam quisquam ipsum. Velit consectetur '\n","         'magnam dolor voluptatem. Quisquam ipsum velit non tempora. Sed ipsum '\n","         'aliquam neque labore. Sed eius numquam ut neque. Magnam amet magnam '\n","         'modi. Sed voluptatem modi est dolor. Quaerat labore adipisci quaerat '\n","         'neque.'}\n"]}],"source":["# get all docs in index 'test'\n","resp = client.search(index=\"test\", query={\"match_all\": {}})\n","\n","# print them\n","print(f\"Got {resp['hits']['total']['value']} hits:\")\n","for hit in resp['hits']['hits']:\n","    pprint(hit[\"_source\"])"]},{"cell_type":"markdown","metadata":{"id":"-PRYrXAaSU3m"},"source":["We can also search for documents that contain a given keyword:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUmR_iX9SU3m","outputId":"90e1ebb4-88d9-4c14-8d48-894d48cbd6c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7 matches.\n","\n","ID: sFkSmIoBzo4VIHJJE4RC\n","Text: Sit porro non voluptatem non. Modi etincidunt ut modi tempora. Aliquam quisquam aliquam dolor dolore dolor modi numquam. Aliquam quisquam magnam modi dolorem dolor quaerat. Velit sit adipisci etincidunt modi.\n","\n","ID: tFkSmIoBzo4VIHJJE4SW\n","Text: Adipisci labore dolore magnam quisquam ipsum. Velit consectetur magnam dolor voluptatem. Quisquam ipsum velit non tempora. Sed ipsum aliquam neque labore. Sed eius numquam ut neque. Magnam amet magnam modi. Sed voluptatem modi est dolor. Quaerat labore adipisci quaerat neque.\n","\n","ID: sVkSmIoBzo4VIHJJE4RU\n","Text: Ipsum dolor etincidunt velit amet sit ut non. Quaerat quaerat dolore sed. Magnam magnam consectetur magnam voluptatem numquam. Voluptatem sed velit ut neque. Eius aliquam amet numquam sed amet magnam. Numquam labore sit adipisci aliquam ipsum.\n","\n","ID: rVkSmIoBzo4VIHJJE4QQ\n","Text: Porro sit neque modi consectetur tempora quaerat dolor. Quisquam numquam aliquam dolorem amet magnam ut. Dolore quiquia quiquia etincidunt etincidunt magnam quiquia ut. Voluptatem amet ut sed. Labore quiquia magnam sit. Ut sed magnam tempora. Non est velit eius labore. Aliquam non dolorem ipsum modi adipisci sed etincidunt.\n","\n","ID: s1kSmIoBzo4VIHJJE4SD\n","Text: Dolorem ut adipisci magnam aliquam sed. Voluptatem quiquia porro dolore est numquam. Sit quiquia amet magnam sed etincidunt voluptatem. Adipisci quiquia dolor consectetur est eius porro. Labore dolore velit numquam. Eius ipsum neque adipisci quaerat eius. Sed ut non est est labore. Tempora adipisci etincidunt ipsum ut voluptatem sit.\n","\n","ID: r1kSmIoBzo4VIHJJE4Qy\n","Text: Amet ipsum numquam est sit etincidunt quiquia. Quisquam ut tempora quisquam tempora neque. Modi eius non dolore voluptatem sed ipsum consectetur. Quiquia adipisci sit quiquia tempora sed quaerat. Non adipisci dolore voluptatem ipsum sed dolor dolorem. Porro quisquam quisquam sed magnam dolorem voluptatem. Neque modi ipsum magnam consectetur labore numquam.\n","\n","ID: rlkSmIoBzo4VIHJJE4Qh\n","Text: Dolore amet porro quiquia numquam. Quisquam quisquam labore sit quaerat labore. Dolore est aliquam magnam velit sed. Porro dolorem sit velit voluptatem adipisci ut amet. Porro dolorem dolor neque sit quiquia. Dolorem sed dolore labore voluptatem dolorem modi. Numquam consectetur non porro non quiquia ipsum porro. Labore voluptatem quisquam ipsum amet velit ipsum.\n"]}],"source":["from elasticsearch_dsl import Search\n","\n","# the following search query specifies the field where we want to search\n","s_obj = Search(using=client, index='test')\n","sq = s_obj.query('match', text='dolor')\n","resp = sq.execute()\n","\n","print(f'Found {len(resp)} matches.')\n","\n","for hit in resp:\n","    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"]},{"cell_type":"markdown","metadata":{"id":"wjU7GXGOSU3m"},"source":["## 4. Counting words and docs\n","\n","`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGNwI6CTSU3n"},"outputs":[],"source":["from elasticsearch.helpers import scan\n","from collections import Counter\n","\n","# Search for all the documents and query the list of (word, frequency) of each one\n","# Totals are accumulated using a Counter\n","word_counts = Counter()\n","sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n","for s in sc:\n","    doc_counts = Counter()   # I place the counter here so that it is overwritten each time, since doc_freq is constant for every doc\n","    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n","    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n","        for t in tv['term_vectors']['text']['terms']:\n","            word = t\n","            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n","            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n","            #pprint(tv['term_vectors']['text']['terms'][t])\n","            word_counts.update({word: count})\n","            doc_counts.update({word: df})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5OKuG92SU3n","outputId":"d023a01a-faec-4063-937c-5eab7d647d79"},"outputs":[{"data":{"text/plain":["[('magnam', 24),\n"," ('ipsum', 22),\n"," ('sed', 22),\n"," ('quisquam', 20),\n"," ('ut', 20),\n"," ('modi', 19),\n"," ('voluptatem', 19),\n"," ('non', 18),\n"," ('aliquam', 17),\n"," ('amet', 17),\n"," ('neque', 17),\n"," ('etincidunt', 16),\n"," ('sit', 16),\n"," ('labore', 16),\n"," ('numquam', 16),\n"," ('adipisci', 15),\n"," ('dolore', 15),\n"," ('quiquia', 15),\n"," ('dolorem', 14),\n"," ('velit', 14),\n"," ('eius', 13),\n"," ('consectetur', 12),\n"," ('est', 12),\n"," ('quaerat', 12),\n"," ('porro', 11),\n"," ('tempora', 10),\n"," ('dolor', 10)]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# show word frequencies\n","word_counts.most_common()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yon1AGHBSU3n","outputId":"56395c2e-fe80-488e-d5ea-caf579c05e55"},"outputs":[{"data":{"text/plain":["[('magnam', 10),\n"," ('non', 10),\n"," ('ut', 10),\n"," ('adipisci', 9),\n"," ('aliquam', 9),\n"," ('amet', 9),\n"," ('consectetur', 9),\n"," ('dolore', 9),\n"," ('ipsum', 9),\n"," ('numquam', 9),\n"," ('quaerat', 9),\n"," ('sed', 9),\n"," ('velit', 9),\n"," ('voluptatem', 9),\n"," ('eius', 8),\n"," ('labore', 8),\n"," ('modi', 8),\n"," ('neque', 8),\n"," ('quisquam', 8),\n"," ('dolor', 7),\n"," ('est', 7),\n"," ('tempora', 6)]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# show doc freq\n","doc_counts.most_common()"]},{"cell_type":"markdown","metadata":{"id":"pHTQzBO9SU3o"},"source":["## 5. Proposed simple exercise\n","\n","To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n","\n","- create an empty index\n","- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n","- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n","- double check that your results coincide with the numbers in theory slides"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZ92g0LlSU3o"},"outputs":[],"source":["# Create an empty index\n","index = Index('exercise1', using=client)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41MiXuUSSU3o","outputId":"1ceee80c-501d-4dc9-e1a8-c908beb4b550"},"outputs":[{"name":"stdout","output_type":"stream","text":["Indexing new text (d7.txt) : four five\n","\n","Indexing new text (d6.txt) : three three three six six\n","\n","Indexing new text (d4.txt) : one two two two two three six six\n","\n","Indexing new text (d5.txt) : three four four four six\n","\n","Indexing new text (d1.txt) : one three\n","\n","Indexing new text (d2.txt) : two two three\n","\n","Indexing new text (d3.txt) : one three four five five five\n","\n"]}],"source":["# Open all documents in the toy-docs folder\n","import os\n","\n","def read_document(file_path):\n","    with open(file_path, 'r') as f:\n","        return f.read()\n","\n","path = os.path.join(os.getcwd(), 'toy-docs')\n","for doc in os.listdir(path):\n","    t = read_document(os.path.join(path, doc))\n","    client.index(index='exercise1', document={'text': t})\n","    print(f'Indexing new text ({doc}) : {t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICvd4-aNSU3p","outputId":"5b06a44e-958f-41cb-d445-736130123f4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'_index': 'exercise1', '_id': '31kpmIoBzo4VIHJJs4Sx', '_version': 1, 'found': True, 'took': 1, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'five': {'doc_freq': 2, 'ttf': 4, 'term_freq': 1, 'tokens': [{'start_offset': 5, 'end_offset': 9}]}, 'four': {'doc_freq': 3, 'ttf': 5, 'term_freq': 1, 'tokens': [{'start_offset': 0, 'end_offset': 4}]}}}}}\n","{'_index': 'exercise1', '_id': '4FkpmIoBzo4VIHJJtIRu', '_version': 1, 'found': True, 'took': 1, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'six': {'doc_freq': 3, 'ttf': 5, 'term_freq': 2, 'tokens': [{'start_offset': 18, 'end_offset': 21}, {'start_offset': 22, 'end_offset': 25}]}, 'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 3, 'tokens': [{'start_offset': 0, 'end_offset': 5}, {'start_offset': 6, 'end_offset': 11}, {'start_offset': 12, 'end_offset': 17}]}}}}}\n","{'_index': 'exercise1', '_id': '4VkpmIoBzo4VIHJJtIR-', '_version': 1, 'found': True, 'took': 0, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'one': {'doc_freq': 3, 'ttf': 3, 'term_freq': 1, 'tokens': [{'start_offset': 0, 'end_offset': 3}]}, 'six': {'doc_freq': 3, 'ttf': 5, 'term_freq': 2, 'tokens': [{'start_offset': 26, 'end_offset': 29}, {'start_offset': 30, 'end_offset': 33}]}, 'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 1, 'tokens': [{'start_offset': 20, 'end_offset': 25}]}, 'two': {'doc_freq': 2, 'ttf': 6, 'term_freq': 4, 'tokens': [{'start_offset': 4, 'end_offset': 7}, {'start_offset': 8, 'end_offset': 11}, {'start_offset': 12, 'end_offset': 15}, {'start_offset': 16, 'end_offset': 19}]}}}}}\n","{'_index': 'exercise1', '_id': '4lkpmIoBzo4VIHJJtISL', '_version': 1, 'found': True, 'took': 0, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'four': {'doc_freq': 3, 'ttf': 5, 'term_freq': 3, 'tokens': [{'start_offset': 6, 'end_offset': 10}, {'start_offset': 11, 'end_offset': 15}, {'start_offset': 16, 'end_offset': 20}]}, 'six': {'doc_freq': 3, 'ttf': 5, 'term_freq': 1, 'tokens': [{'start_offset': 21, 'end_offset': 24}]}, 'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 1, 'tokens': [{'start_offset': 0, 'end_offset': 5}]}}}}}\n","{'_index': 'exercise1', '_id': '41kpmIoBzo4VIHJJtISZ', '_version': 1, 'found': True, 'took': 0, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'one': {'doc_freq': 3, 'ttf': 3, 'term_freq': 1, 'tokens': [{'start_offset': 0, 'end_offset': 3}]}, 'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 1, 'tokens': [{'start_offset': 4, 'end_offset': 9}]}}}}}\n","{'_index': 'exercise1', '_id': '5FkpmIoBzo4VIHJJtISj', '_version': 1, 'found': True, 'took': 0, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 1, 'tokens': [{'start_offset': 8, 'end_offset': 13}]}, 'two': {'doc_freq': 2, 'ttf': 6, 'term_freq': 2, 'tokens': [{'start_offset': 0, 'end_offset': 3}, {'start_offset': 4, 'end_offset': 7}]}}}}}\n","{'_index': 'exercise1', '_id': '5VkpmIoBzo4VIHJJtISv', '_version': 1, 'found': True, 'took': 0, 'term_vectors': {'text': {'field_statistics': {'sum_doc_freq': 19, 'doc_count': 7, 'sum_ttf': 31}, 'terms': {'five': {'doc_freq': 2, 'ttf': 4, 'term_freq': 3, 'tokens': [{'start_offset': 15, 'end_offset': 19}, {'start_offset': 20, 'end_offset': 24}, {'start_offset': 25, 'end_offset': 29}]}, 'four': {'doc_freq': 3, 'ttf': 5, 'term_freq': 1, 'tokens': [{'start_offset': 10, 'end_offset': 14}]}, 'one': {'doc_freq': 3, 'ttf': 3, 'term_freq': 1, 'tokens': [{'start_offset': 0, 'end_offset': 3}]}, 'three': {'doc_freq': 6, 'ttf': 8, 'term_freq': 1, 'tokens': [{'start_offset': 4, 'end_offset': 9}]}}}}}\n","[('three', 8), ('two', 6), ('four', 5), ('six', 5), ('five', 4), ('one', 3)]\n","[('three', 6), ('four', 3), ('one', 3), ('five', 2)]\n"]}],"source":["# Obtain word-count pairs\n","word_counts = Counter()\n","sc = scan(client, index='exercise1', query={\"query\" : {\"match_all\": {}}})\n","for s in sc:\n","    doc_counts = Counter()   # I place the counter here so that it is overwritten each time, since doc_freq is constant for every doc\n","    tv = client.termvectors(index='exercise1', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n","    print(tv)\n","    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n","        for word in tv['term_vectors']['text']['terms']:\n","            count = tv['term_vectors']['text']['terms'][word]['term_freq']\n","            df = tv['term_vectors']['text']['terms'][word]['doc_freq']\n","            word_counts.update({word: count})\n","            doc_counts.update({word: df})\n","\n","# show word frequencies\n","print(word_counts.most_common())\n","\n","# show doc freq\n","print(doc_counts.most_common())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKZFxWvxSU3p","outputId":"134cd844-074d-4733-e905-3ed2e7edbab3"},"outputs":[{"data":{"text/plain":["[{'five': 1, 'four': 1, 'one': 0, 'six': 0, 'three': 0, 'two': 0},\n"," {'five': 0, 'four': 0, 'one': 0, 'six': 1, 'three': 1, 'two': 0},\n"," {'five': 0, 'four': 0, 'one': 1, 'six': 1, 'three': 1, 'two': 1},\n"," {'five': 0, 'four': 1, 'one': 0, 'six': 1, 'three': 1, 'two': 0},\n"," {'five': 0, 'four': 0, 'one': 1, 'six': 0, 'three': 1, 'two': 0},\n"," {'five': 0, 'four': 0, 'one': 0, 'six': 0, 'three': 1, 'two': 1},\n"," {'five': 1, 'four': 1, 'one': 1, 'six': 0, 'three': 1, 'two': 0}]"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Obtain word-count pairs - Boolean model\n","bool_matrix = []\n","sc = scan(client, index='exercise1', query={\"query\" : {\"match_all\": {}}})\n","for s in sc:\n","    doc_dict = {'five': 0, 'four': 0, 'one': 0, 'six': 0, 'three': 0, 'two': 0}\n","    tv = client.termvectors(index='exercise1', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n","\n","    for word in tv['term_vectors']['text']['terms']:\n","        doc_dict[word] = 1\n","\n","    bool_matrix.append(doc_dict)\n","\n","\n","# show word frequencies\n","bool_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHY_WPBbSU3p","outputId":"be4bdb07-9aef-412d-ab10-e9adafc71200"},"outputs":[{"data":{"text/plain":["[{'five': 1.8073549220576042,\n","  'four': 1.222392421336448,\n","  'one': 0.0,\n","  'six': 0.0,\n","  'three': 0.0,\n","  'two': 0.0},\n"," {'five': 0.0,\n","  'four': 0.0,\n","  'one': 0.0,\n","  'six': 0.8149282808909654,\n","  'three': 0.22239242133644802,\n","  'two': 0.0},\n"," {'five': 0.0,\n","  'four': 0.0,\n","  'one': 0.305598105334112,\n","  'six': 0.611196210668224,\n","  'three': 0.055598105334112004,\n","  'two': 1.8073549220576042},\n"," {'five': 0.0,\n","  'four': 1.222392421336448,\n","  'one': 0.0,\n","  'six': 0.4074641404454827,\n","  'three': 0.07413080711214934,\n","  'two': 0.0},\n"," {'five': 0.0,\n","  'four': 0.0,\n","  'one': 1.222392421336448,\n","  'six': 0.0,\n","  'three': 0.22239242133644802,\n","  'two': 0.0},\n"," {'five': 0.0,\n","  'four': 0.0,\n","  'one': 0.0,\n","  'six': 0.0,\n","  'three': 0.11119621066822401,\n","  'two': 1.8073549220576042},\n"," {'five': 1.8073549220576042,\n","  'four': 0.4074641404454827,\n","  'one': 0.4074641404454827,\n","  'six': 0.0,\n","  'three': 0.07413080711214934,\n","  'two': 0.0}]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# Obtain word-count pairs - Boolean model\n","import math\n","\n","\n","sc = scan(client, index='exercise1', query={\"query\" : {\"match_all\": {}}})\n","\n","f_dict = []\n","df_dict = {'five': 0, 'four': 0, 'one': 0, 'six': 0, 'three': 0, 'two': 0}\n","for s in sc:\n","    fs_dict = {'five': 0, 'four': 0, 'one': 0, 'six': 0, 'three': 0, 'two': 0}\n","    tv = client.termvectors(index='exercise1', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n","\n","    D = tv['term_vectors']['text']['field_statistics']['doc_count']\n","\n","    for word in tv['term_vectors']['text']['terms']:\n","        fs_dict[word] = tv['term_vectors']['text']['terms'][word]['term_freq']\n","        df_dict[word] = tv['term_vectors']['text']['terms'][word]['doc_freq']\n","\n","    f_dict.append(fs_dict)\n","\n","weight_matrix = []\n","for i in range(len(f_dict)):\n","    doc_dict = {'five': 0, 'four': 0, 'one': 0, 'six': 0, 'three': 0, 'two': 0}\n","\n","    maxf = max(f_dict[i].values())\n","    for word in doc_dict.keys():\n","        doc_dict[word] = (f_dict[i][word]/maxf)*(math.log(D/df_dict[word], 2))\n","\n","    weight_matrix.append(doc_dict)\n","\n","# show word frequencies\n","weight_matrix"]},{"cell_type":"markdown","metadata":{"id":"cGZEHn40SU3q"},"source":["## 6. Cleanup\n","\n","Finally, we remove the test index.."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RopTYsdhSU3q","outputId":"a381d479-b0ef-43a0-d293-ea570fb139cb"},"outputs":[{"data":{"text/plain":["ObjectApiResponse({'acknowledged': True})"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["index.delete()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"nav_menu":{"height":"135px","width":"252px"},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}