{"cells":[{"cell_type":"markdown","metadata":{"id":"kKaAZFhrpgtn"},"source":["**Exercise 1:**  \n","\n","Make sure you understand the algorithm for implementing search described in the lecture notes. Both slow and efficient versions. Describe\n","the number of sums you need to do in both slow and quick versions for the following toy example with a vocabulary of size 4 and four documents:\n","\n","- $q = 0,1,1,0$\n","\n","- document-term matrix:\n","<center>\n","\n","\n","|        | t1  | t2  | t3  | t4  |\n","|--------|-----|-----|-----|-----|\n","| **d1** | 1.2 | 0.0 | 0.0 | 0.0 |\n","| **d2** | 0.7 | 0.3 | 1.5 | 0.1 |\n","| **d3** | 0.0 | 0.0 | 0.0 | 0.7 |\n","| **d4** | 2.0 | 0.0 | 0.0 | 0.0 |\n","\n","</center>\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8fgAgTtpgtq"},"outputs":[],"source":["q = [0, 1, 1, 0]\n","DMat = [[1.2, 0, 0, 0], [0.7, 0.3, 1.5, 0.1], [0, 0, 0, 0.7], [2, 0, 0, 0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm_0bFO1pgtr","outputId":"b33cb4a1-62a0-45ee-a9ff-77621fa68daa"},"outputs":[{"name":"stdout","output_type":"stream","text":["16\n"]}],"source":["## Slow version\n","\n","count = 0\n","\n","for i in range(len(DMat)):\n","    for j in range(len(q)):\n","        count = count + 1\n","\n","print(count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_zoWnMmpgts","outputId":"9291c2ac-999c-49bd-f588-c06fa8189171"},"outputs":[{"name":"stdout","output_type":"stream","text":["8\n"]}],"source":["## Fast version\n","\n","count = 0\n","DMatT = [[DMat[i][k] for i in range(len(DMat))] for k in range(len(DMat[0]))]\n","\n","for j in range(len(q)):\n","    if q[j] !=0:\n","        for i in range(len(DMatT[j])):\n","            count = count + 1\n","\n","print(count)"]},{"cell_type":"markdown","metadata":{"id":"eq7FwB2Mpgtt"},"source":["**Exercise 2:**\n","\n","Implement the quick version; run both slow and quick versions and report times (as a reference, in my old laptop it takes around 5m30s to run the slow version in the code above). Make sure both versions return the same answer. Note that you will need to build an inverted index in order to implement the efficient version as explained in class; it may take time but this is done once for all queries, and can be done \"off-line\".\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwXfuIaKpgtt"},"outputs":[],"source":["from elasticsearch.helpers import scan\n","from pprint import pprint\n","from elasticsearch import Elasticsearch\n","from elasticsearch_dsl import Index, analyzer, tokenizer\n","from elasticsearch.exceptions import NotFoundError\n","import tqdm\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-fwCk7Opgtt","outputId":"0d9d6e51-6e16-4bfd-cbe8-c6b8f87a090c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Indexing 58103 files\n","Reading files ...\n","Index settings= {'arxiv': {'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}}, 'number_of_shards': '1', 'provided_name': 'arxiv', 'creation_date': '1697190074277', 'analysis': {'analyzer': {'default': {'filter': ['snowball'], 'type': 'custom', 'tokenizer': 'letter'}}}, 'number_of_replicas': '1', 'uuid': 'c_wu2SHWR6eYuiBELFOZ7w', 'version': {'created': '8100099'}}}}}\n","Indexing ...\n"]}],"source":["client = Elasticsearch(\"http://localhost:9200\", request_timeout=1000)\n","\n","my_ind = Index('arxiv', using=client)\n","my_ind.settings(number_of_shards=1)\n","\n","try:\n","    # drop if exists\n","    my_ind.delete()\n","except NotFoundError:\n","    pass\n","\n","# create it\n","my_ind.create()\n","\n","# create new analyzer\n","my_analyzer = analyzer('default',\n","    type='custom',\n","    tokenizer=tokenizer('letter'),\n","    filter=['lowercase', 'asciifolding', 'stop', 'snowball']\n",")\n","\n","# close to update analyzer to custom `my_analyzer`\n","my_ind.close()\n","my_ind.analyzer(my_analyzer)\n","my_ind.save()\n","my_ind.open()\n","\n","%run -i IndexFilesPreprocess.py --path=\"/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab 03/arxiv\" --index=arxiv --token='letter' --filter='snowball'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LONOMCtRpgtu"},"outputs":[],"source":["import math\n","\n","def encode_doc(doc_id):\n","    doc_dict = {}\n","    tv = client.termvectors(index='arxiv', id=doc_id, fields=['text'], term_statistics=True, positions=False)\n","    D = tv['term_vectors']['text']['field_statistics']['doc_count']\n","    maxf = 0\n","    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n","        for word in tv['term_vectors']['text']['terms']:\n","            f = tv['term_vectors']['text']['terms'][word]['term_freq']\n","            if f > maxf:\n","                maxf = f\n","\n","            df = tv['term_vectors']['text']['terms'][word]['doc_freq']\n","            doc_dict[word] = (f/maxf)*(math.log(D/df, 2))\n","\n","    return doc_dict\n","\n","def scalar_product(doc1, doc2):\n","    prod = 0\n","    for word in doc1.keys():\n","        if word in doc2.keys():\n","            prod += doc1[word]*doc2[word]\n","\n","    return prod\n","\n","def my_norm(doc):\n","    return math.sqrt(scalar_product(doc, doc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rj9Cd8-3pgtu"},"outputs":[],"source":["## SLOW VERSION\n","def SlowSearch(query, r):\n","    sims = dict()\n","\n","    l2query  = np.sqrt(len(query.split()))  # l2 of query assuming 0-1 vector representation\n","\n","    # get nr. of docs; just for the progress bar\n","    ndocs = int(client.cat.count(index='arxiv', format = \"json\")[0]['count'])\n","\n","    # scan through docs, compute cosine sim between query and each doc\n","    for s in tqdm.tqdm(scan(client, index='arxiv', query={\"query\" : {\"match_all\": {}}}), total=ndocs):\n","        docid = s['_source']['path']   # use path as id\n","        weights = encode_doc(s['_id'])   # gets weights as a python dict of term -> weight\n","        sims[docid] = 0.0\n","        for w in query.split():  # gets terms as a list\n","            if w in weights.keys():    # probably need to do something fancier to make sure that word is in vocabulary etc.\n","                sims[docid] += weights[w]   # accumulates if w in current doc\n","        # normalize sim\n","        sims[docid] /= (l2query*my_norm(weights))\n","    # now sort by cosine similarity\n","    sorted_answer = sorted(sims.items(), key=lambda kv: kv[1], reverse=True)\n","    return sorted_answer[:r]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsUgxShupgtu","outputId":"c39094e5-c3c0-41bc-e4a1-54430e561888"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 58103/58103 [06:30<00:00, 148.73it/s]\n"]}],"source":["def inverted_file():\n","    PLists = dict()\n","    ndocs = int(client.cat.count(index='arxiv', format = \"json\")[0]['count'])\n","\n","    for s in tqdm.tqdm(scan(client, index='arxiv', query={\"query\" : {\"match_all\": {}}}), total=ndocs):\n","        docid = s['_source']['path']\n","        weights = encode_doc(s['_id'])\n","        n_weights = my_norm(weights)\n","\n","        for w in weights.keys():\n","            try:\n","                PLists[w] += [(docid, weights[w]/n_weights)]\n","            except:\n","                PLists[w] = [(docid, weights[w]/n_weights)]\n","\n","    return PLists\n","\n","PostLists = inverted_file()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aT_l7m-ppgtv"},"outputs":[],"source":["def FastSearch(query, r, PL):\n","    sims = dict()\n","\n","    l2query  = np.sqrt(len(query.split()))  # l2 of query assuming 0-1 vector representation\n","\n","    # get nr. of docs; just for the progress bar\n","    ndocs = int(client.cat.count(index='arxiv', format = \"json\")[0]['count'])\n","\n","    # scan through words in the query, compute cosine sim between query and each doc\n","    for w in query.split():\n","        L = PL[w] # find posting list for the word\n","        for (docid, weight) in L:\n","            try:\n","                sims[docid] += weight/l2query # accumulates similarities\n","            except:\n","                sims[docid] = weight/l2query\n","\n","    # now sort by cosine similarity\n","    sorted_answer = sorted(sims.items(), key=lambda kv: kv[1], reverse=True)\n","    return dict(sorted_answer[:r])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyuOxFMOpgtv","outputId":"6a0e9434-7d06-4f0e-983e-2d12ee1d7d62"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 58103/58103 [07:11<00:00, 134.56it/s]\n"]}],"source":["slow_answer = SlowSearch('computer magic', 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zi-Fc2Vapgtv"},"outputs":[],"source":["fast_answer = FastSearch('computer magic', 10, PostLists)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZGSP4PEpgtv","outputId":"dd5530bc-5ff9-40ce-da5a-7089d6b2649a"},"outputs":[{"name":"stdout","output_type":"stream","text":["('/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab 03/arxiv/quant-ph.updates.on.arXiv.org/000650', 0.2882522830471679)\n","('/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab 03/arxiv/quant-ph.updates.on.arXiv.org/000650', 0.2882522830471678)\n"]}],"source":["for i in range(10):\n","    if fast_answer[i] != slow_anwer[i]:\n","        print(fast_answer[i])\n","        print(slow_anwer[i])"]},{"cell_type":"markdown","metadata":{"id":"ere203pMpgtw"},"source":["**Exercise 3:**\n","\n","Compare the results for a few sample queries that you get from your quick version and ElasticSearch search. Do you get similar results? Which is faster?\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NK1AgPKnpgtw"},"outputs":[],"source":["from elasticsearch_dsl import Search\n","from elasticsearch_dsl.query import Q\n","\n","def ESSearch(my_query, r):\n","    s = Search(using=client, index='arxiv')\n","\n","    qsplit = my_query.split()\n","    q = Q('query_string',query=qsplit[0])\n","    for w in qsplit[1:]:\n","        q = q & Q('query_string',query=w)\n","\n","    s = s.query(q)\n","\n","    answer = dict()\n","    for a in s[0:r].execute():  # only returns a specific number of results\n","        answer[a.path] = a.meta.score\n","\n","    return answer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODGozRp5pgtw"},"outputs":[],"source":["def print_rank(r, answer1, answer2):\n","    docs1 = list(answer1.keys())\n","    docs2 = list(answer2.keys())\n","    print(\" \", \"  ES  \", \" FAST \")\n","    for k in range(min(r, len(docs1), len(docs2))):\n","        # print('-----------------------------------------------------------------------------------')\n","        print(str(k), str(docs1[k][-6:]), str(docs2[k][-6:]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3Us3k-xpgtw"},"outputs":[],"source":["answer_ES = ESSearch('computer magic', 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFn2jFrxpgtw"},"outputs":[],"source":["answer_fast = FastSearch('computer magic', 10, PostLists)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Dgua9CSpgtw","outputId":"53b9194f-0628-4871-deda-85439e27b3b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["    ES    FAST \n","0 000677 001475\n","1 000650 000650\n","2 001475 000265\n","3 000992 000955\n","4 001477 002825\n","5 013376 000677\n","6 006074 000255\n","7 001652 000896\n","8 001630 003482\n","9 000521 004798\n"]}],"source":["print_rank(10, answer_ES, answer_fast)"]},{"cell_type":"markdown","metadata":{"id":"QtyNyEFMpgtw"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDGjkkespgtw","outputId":"7cc4e768-62fe-4c06-932d-c69b53294c38"},"outputs":[{"name":"stdout","output_type":"stream","text":["    ES    FAST \n","0 011045 011045\n","1 010049 000616\n","2 009349 001260\n","3 012590 010049\n","4 008869 008869\n","5 012600 002067\n","6 000616 008734\n","7 004880 012006\n","8 004320 012511\n","9 003245 012118\n"]}],"source":["answer_ES = ESSearch('star brown', 10)\n","answer_fast = FastSearch('star brown', 10, PostLists)\n","\n","print_rank(10, answer_ES, answer_fast)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkdSQ__xpgtw","outputId":"19e86b7f-62d2-4f45-de27-70093111b734"},"outputs":[{"name":"stdout","output_type":"stream","text":["    ES    FAST \n","0 002772 002147\n","1 001639 003164\n","2 012669 017650\n","3 005541 007419\n","4 014669 001236\n","5 014695 006959\n"]},{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab 04/lab4.ipynb Celda 23\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m answer_ES \u001b[39m=\u001b[39m ESSearch(\u001b[39m'\u001b[39m\u001b[39mplanet star Newton\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m10\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m answer_fast \u001b[39m=\u001b[39m FastSearch(\u001b[39m'\u001b[39m\u001b[39mplanet star Newton\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m10\u001b[39m, PostLists)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m print_rank(\u001b[39m10\u001b[39;49m, answer_ES, answer_fast)\n","\u001b[1;32m/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab 04/lab4.ipynb Celda 23\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m  ES  \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m FAST \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(r):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# print('-----------------------------------------------------------------------------------')\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lauragarcialopez/Documents/uni/4o/4A/CAI/Labs/Lab%2004/lab4.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(k), \u001b[39mstr\u001b[39m(docs1[k][\u001b[39m-\u001b[39m\u001b[39m6\u001b[39m:]), \u001b[39mstr\u001b[39m(docs2[k][\u001b[39m-\u001b[39m\u001b[39m6\u001b[39m:]))\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"source":["answer_ES = ESSearch('planet star Newton', 10)\n","answer_fast = FastSearch('planet star Newton', 10, PostLists)\n","\n","print_rank(10, answer_ES, answer_fast)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMQTNJpopgtx"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}